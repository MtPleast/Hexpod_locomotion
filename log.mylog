现在到了toyrep调参 vrep验证阶段
如果没有footorder，腿交叉的现象比较严重，应该加上

加了footorder训了5300轮，机器人出现撞到障碍的现象
    换做footdistance，正在训练
观察到的机器人疯狂旋转可能是因为 detorch的时候角度求解有误所致
    已修正

改成一个通过reward 软调整policy的体系

修改textlogger的bug
    问题原因通过 actorcritic.logger引用的的对象和直接import logger的对象不一样
    应该算是解决了这个问题

计划：现在正在进行的实验：
    疯狂训练计划，一直在服务器上训练机器人，观察其reward曲线
    写一些其它的reward调整项
    
服务器跑出bug，需要de



EXPERIMENTS：
    无footorder，有footdistance，有pain， 2900轮，
    出现了远离目标的现象
    仍有腿的角度很近的现象

    有footorder，有footdistance，有pain， 4800轮，
        能走路
        能略微避障
        能跨越复杂低障碍（但是出现踩上去的现象）
        为了避障出现腿交叉引起爆炸

        又是为了避障出现腿交叉

        对于大障碍物的躲避问题较大

    有footorder，有footdistance，有pain， 7600轮，
    平均reward接近但是不及 4800
    简单障碍成功避绕
    夹在两个障碍之间出现来回躲避导致最后爆炸

    有footorder，有footdistance，有pain， 9200轮，
    可以做到一个小时被障碍卡住而不爆炸，不过最后还是没能走到终点
    仅有这以此测试


exp3的结果
    训练的painful太大了，使得机器人不知道往前走
    只有foot distance感觉也差不多，没有爆炸

exp4：
    改变了超参数，critic0.005 actor的lerning rate 0.001
    N=5改成N=2

exp5 在蒋力服务器上跑的10100
    跌跌涨涨，最后回不到巅峰状态
    方向能力不足，能被一个障碍物卡住，会踩到小障碍，总之很糟糕，能在一个大障碍面前做往复运动得到reward

exp6 蒋力服务器上，原价值函数，更远的视野
    AI服务器上， 继续减小pain和danger的factor
    感觉服务器上的结果和我电脑上的画风不一样。。。。
    疯狂一波，在自己电脑上也跑一份

    从reward来看，效果不佳
    看了网上的经验，换了超参数
    

2019-2-12 分析
    需要调查：
        为什么减小了LR重新启动后reward 狂跌？？
    有几个可以尝试的方法：
        更换DDPG
        learning Rate， reward， 网络结构， L2 regulation， batch_size

!!!!重大问题
测试了两个模型都直着装上障碍物，不知是模型问题还是环境问题
换个之前能行的模型
    还是能行！！！！！
    从pod_log来看，是有撞到topo的情况
    在oldenv里面令其观测到障碍物就输出一下observed ， 也发现其大量出现观测到 地面高度不是零，但这不代表出现在机器人输入里面
发现19300的reward又上去了，测试这个模型的动作
    仍然是直线走
    但是可以绕过一个障碍物

    这应该是正则化项的作用


不知道哪个模型好。。。。
    对于blue一号地图的测试：
        blue一号地图：
            set_map_util(Barrier,0.05,0.1,[[1,0,0.05]]*12)
            set_map_util(Wall,0.25,0.5,[[2,0,0.25]]*6)

    机器人将使用载入史册的9200 比10500好，比savior2000 好
    9200使用旧的 obs, 是exp1 9200
    exp1 2900 直接装上去
    exp1 4800 在障碍物前踌躇，忽然后退并试图绕过，但是最后还是装上去
    exp1 7600 在前面踌躇
    exp1 9200 可以
    exp1 10700 不行

    savior： 使用assert obs = 15的输入
    savior 2500 不会往前
    savior 2700 会撞
    savior 10700 会撞
    savior 10600 会撞
    savior 13000 会撞上小障碍
    savior 15000 会撞上 轻微犹豫

    hopior 10000 会撞上
    hopior 11000 犹豫,会撞上
    hopior 12000 犹豫
    hopior 13000 会撞
    hopior 22000 前面绕过比较流畅，后面不接近目标！
    hopior 25000 踌躇，诡异
    hopior 28000 踌躇，诡异
    hopior 30000 踌躇，缓慢绕过、接近

    22300 用的larger model
    22300 非常流畅！！！！！
    35300   流畅绕过障碍物之后卡死
    大问题：
        在toy 里面走的好在blue里面走不出来
        ori设置反了
    
目前的情况：
    录像完毕，开环蒙眼走效果比闭环slam好
    两大问题：上层不收敛，以及没有下层
    已经开发出了高效看机器人策略的方法，前面的观察来看，我们需要一个敢于往前走，同时能够绕过障碍物的机器人，幸好有22300，否则整个实验是跪了

    可能因为机器人已经发现踌躇不定的好处，等待max step耗尽，自己就可以不得到那个很负的reward
        面对一个障碍，有三个选项： 不往前，往前，撞死，
                                把撞死的penalty 调小可能有用