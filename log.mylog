现在到了toyrep调参 vrep验证阶段
如果没有footorder，腿交叉的现象比较严重，应该加上

加了footorder训了5300轮，机器人出现撞到障碍的现象
    换做footdistance，正在训练
观察到的机器人疯狂旋转可能是因为 detorch的时候角度求解有误所致
    已修正

改成一个通过reward 软调整policy的体系

修改textlogger的bug
    问题原因通过 actorcritic.logger引用的的对象和直接import logger的对象不一样
    应该算是解决了这个问题

计划：现在正在进行的实验：
    疯狂训练计划，一直在服务器上训练机器人，观察其reward曲线
    写一些其它的reward调整项
    
服务器跑出bug，需要de



EXPERIMENTS：
    无footorder，有footdistance，有pain， 2900轮，
    出现了远离目标的现象
    仍有腿的角度很近的现象

    有footorder，有footdistance，有pain， 4800轮，
        能走路
        能略微避障
        能跨越复杂低障碍（但是出现踩上去的现象）
        为了避障出现腿交叉引起爆炸

        又是为了避障出现腿交叉

        对于大障碍物的躲避问题较大

    有footorder，有footdistance，有pain， 7600轮，
    平均reward接近但是不及 4800
    简单障碍成功避绕
    夹在两个障碍之间出现来回躲避导致最后爆炸

    有footorder，有footdistance，有pain， 9200轮，
    可以做到一个小时被障碍卡住而不爆炸，不过最后还是没能走到终点
    仅有这以此测试


exp3的结果
    训练的painful太大了，使得机器人不知道往前走
    只有foot distance感觉也差不多，没有爆炸

exp4：
    改变了超参数，critic0.005 actor的lerning rate 0.001
    N=5改成N=2

exp5 在蒋力服务器上跑的10100
    跌跌涨涨，最后回不到巅峰状态
    方向能力不足，能被一个障碍物卡住，会踩到小障碍，总之很糟糕，能在一个大障碍面前做往复运动得到reward

exp6 蒋力服务器上，原价值函数，更远的视野
    AI服务器上， 继续减小pain和danger的factor
    感觉服务器上的结果和我电脑上的画风不一样。。。。
    疯狂一波，在自己电脑上也跑一份

    从reward来看，效果不佳
    看了网上的经验，换了超参数
    

2019-2-12 分析
    需要调查：
        为什么减小了LR重新启动后reward 狂跌？？
    有几个可以尝试的方法：
        更换DDPG
        learning Rate， reward， 网络结构， L2 regulation， batch_size

!!!!重大问题
测试了两个模型都直着装上障碍物，不知是模型问题还是环境问题
换个之前能行的模型
    还是能行！！！！！
    从pod_log来看，是有撞到topo的情况
    在oldenv里面令其观测到障碍物就输出一下observed ， 也发现其大量出现观测到 地面高度不是零，但这不代表出现在机器人输入里面
发现19300的reward又上去了，测试这个模型的动作
    仍然是直线走
    但是可以绕过一个障碍物

    这应该是正则化项的作用